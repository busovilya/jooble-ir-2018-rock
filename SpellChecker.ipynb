{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import pickle\n",
    "import configparser\n",
    "\n",
    "from flask import Flask\n",
    "from flask import request\n",
    "from collections import Counter\n",
    "from analyzer import tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellChecker:\n",
    "    def __init__(self, model):\n",
    "        self.model = model    \n",
    "        self.WORDS = self.words()\n",
    "                \n",
    "    def words(self):\n",
    "        return set(self.model.keys())\n",
    "    \n",
    "    def P(self, word): \n",
    "        return self.model.get(word, 0)\n",
    "\n",
    "    def correction(self, word): \n",
    "        \"Most probable spelling correction for word.\"\n",
    "        return max(self.candidates(word), key=self.P)\n",
    "    \n",
    "    def correct(self, words):\n",
    "        for word in words:\n",
    "            if len(word) > 10 and word not in self.WORDS:\n",
    "                return self.segment(word)\n",
    "        return [self.correction(word) for word in words]\n",
    "\n",
    "    def candidates(self, word): \n",
    "        \"Generate possible spelling corrections for word.\"\n",
    "        return (self.known([word]) or self.known(self.edits1(word)) or \n",
    "                    self.known(self.edits2(word)) or [word])\n",
    "\n",
    "    def known(self, words): \n",
    "        \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "        return set(words) & self.WORDS\n",
    "\n",
    "\n",
    "    def edits1(self, word):\n",
    "        \"All edits that are one edit away from `word`.\"\n",
    "        #letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        letters = 'абвгдежзийклмнопрстуфхцчшщъыьэюя'\n",
    "        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "        deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "        replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "        inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "        self.edits_1 = list(set(deletes + transposes + replaces + inserts))\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "      \n",
    "    def edit(self, word):\n",
    "        \"All edits that are one edit away from `word`.\"\n",
    "        #letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        letters = 'абвгдежзийклмнопрстуфхцчшщъыьэюя'\n",
    "        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "        deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "        replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "        inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "        \n",
    "\n",
    "    def edits2(self, word): \n",
    "        \"All edits that are two edits away from `word`.\"\n",
    "        answer = self.edit(list(self.edits_1)[0])\n",
    "        for w in list(self.edits_1)[1:]:\n",
    "            answer |= self.edit(w)\n",
    "        return answer   \n",
    "    \n",
    "    def Pwords(self, words):\n",
    "        \"Probability of words, assuming each word is independent of others.\"\n",
    "        return self.product(self.model.get(w,1e-9) for w in words)\n",
    "\n",
    "    def product(self, nums):\n",
    "        \"Multiply the numbers together.  (Like `sum`, but with multiplication.)\"\n",
    "        result = 1\n",
    "        for x in nums:\n",
    "            result *= x\n",
    "        return result\n",
    "    \n",
    "    def splits(self, text, start=0, L=20):\n",
    "        \"Return a list of all (first, rest) pairs; start <= len(first) <= L.\"\n",
    "        return [(text[:i], text[i:]) \n",
    "                for i in range(start, min(len(text), L)+1)]\n",
    "\n",
    "    def segment(self, text):\n",
    "        \"Return a list of words that is the most probable segmentation of text.\"\n",
    "        if not text: \n",
    "            return []\n",
    "        else:\n",
    "            candidates = ([first] + self.segment(rest) \n",
    "                          for (first, rest) in self.splits(text, 1))\n",
    "            return max(candidates, key=self.Pwords)        \n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model for spell checking\n",
    "'''\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "path = config['Data']['Path']\n",
    "'''\n",
    "\n",
    "all_words = list()  \n",
    "for root, dirs, files in os.walk(\"../Data\"):  \n",
    "    for filename in files:\n",
    "        if 'list_of_words' in filename:\n",
    "            with open('../Data/' + filename, 'rb') as file:\n",
    "                try: \n",
    "                    all_words += pickle.load(file)\n",
    "                except JSONDecodeError:\n",
    "                    print(\"Can't read file \" + filename)\n",
    "    \n",
    "probability_dist = Counter(all_words)\n",
    "N = sum(probability_dist.values())\n",
    "for key in probability_dist:\n",
    "    probability_dist[key] /= N\n",
    "    \n",
    "sc = SpellChecker(probability_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:13539/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [09/Dec/2018 00:32:10] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:32:14] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:34:39] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:34:41] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:34:47] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:34:50] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:35:13] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:36:33] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:37:41] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:39:23] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:40:08] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:40:46] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:41:41] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:42:25] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:44:43] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:45:13] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:46:38] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:49:19] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:50:04] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:53:54] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:55:16] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 00:55:51] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 11:20:45] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 11:22:12] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 11:26:08] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 11:26:19] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 11:28:45] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 11:29:22] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 11:30:03] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 11:30:26] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 11:31:35] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 11:32:01] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 11:41:10] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 11:45:54] \"POST /spellchecker HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2018 11:46:03] \"POST /spellchecker HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/spellchecker\", methods=[\"POST\"])\n",
    "def checking():\n",
    "    json_data = request.json\n",
    "    query = json_data['query']\n",
    "        \n",
    "    # tokenizing (create list of lists where each list is separate token)\n",
    "    tokenized = tokenizer.tokenize(query) \n",
    "    \n",
    "    # words - list of tokens from query\n",
    "    words = [item for sublist in tokenized for item in sublist]\n",
    "    # create list of correct words\n",
    "    correct_words = sc.correct(words)\n",
    "    \n",
    "    state = 0\n",
    "    correct_query = query\n",
    "    for i in zip(words, correct_words):\n",
    "        if i[0] != i[1]:\n",
    "            state = 1\n",
    "            correct_query = ' '.join(correct_words)\n",
    "        \n",
    "    return json.dumps({\"status\":\"ok\", \"got_data\":json_data['query'], \n",
    "                       \"processed_data\": correct_query, \"state\": state}, ensure_ascii=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=13539)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
